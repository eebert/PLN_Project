{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 0/8773 oraciones (0.00%)\n",
      "Procesando: 877/8773 oraciones (10.00%)\n",
      "Procesando: 1754/8773 oraciones (19.99%)\n",
      "Procesando: 2631/8773 oraciones (29.99%)\n",
      "\n",
      "omitiendo Entidad 'D.S.00' no encontrada en el texto.\n",
      "Contexto: además, sujetos de créditos [ENTIDAD] dejar de referirme al importante\n",
      "Oración: No puedo dejar de referirme al importante D.S. 009 y al D.S. 011, que consolidan los mercados de tierras y permiten a los hombres del campo organizarse como mejor convenga a sus intereses; ser, además, sujetos de créditos.\n",
      "\n",
      "omitiendo Entidad 'D.S.0' no encontrada en el texto.\n",
      "Contexto: además, sujetos de créditos [ENTIDAD] dejar de referirme al importante\n",
      "Oración: No puedo dejar de referirme al importante D.S. 009 y al D.S. 011, que consolidan los mercados de tierras y permiten a los hombres del campo organizarse como mejor convenga a sus intereses; ser, además, sujetos de créditos.\n",
      "\n",
      "omitiendo Entidad 'Sr.Ministro de Energía y Minas' no encontrada en el texto.\n",
      "Contexto: , 500 kilómetros por año [ENTIDAD], tome nota, 1\n",
      "Oración: Sr. Ministro de Energía y Minas, tome nota, 1,500 kilómetros por año.\n",
      "Procesando: 3508/8773 oraciones (39.99%)\n",
      "Procesando: 4385/8773 oraciones (49.98%)\n",
      "Procesando: 5262/8773 oraciones (59.98%)\n",
      "Procesando: 6139/8773 oraciones (69.98%)\n",
      "\n",
      "omitiendo Entidad 'Decreto de Urgencia N�� 017' no encontrada en el texto.\n",
      "Contexto: efectos del COVID - 19 [ENTIDAD] mediante el Decreto de Urgencia\n",
      "Oración: No obstante, lo anterior, mediante el Decreto de Urgencia Nº 017-2022 se han destinado 96.8 millones de soles para atender las demandas de las ollas comunes y enfrentar el incremento de los precios producto del contexto internacional y de los efectos del COVID-19.\n",
      "Procesando: 7016/8773 oraciones (79.97%)\n",
      "Procesando: 7893/8773 oraciones (89.97%)\n",
      "Procesando: 8770/8773 oraciones (99.97%)\n",
      "Procesamiento completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TFM_Project\\PLN_Project\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# notebooks/05_RoBERTa.ipynb\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configuración del entorno del notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils.file_utils import read_excel_file, save_data_to_excel\n",
    "from utils.advanced_ner_utils import perform_ner_with_roberta\n",
    "\n",
    "from config import XLSX_DIRECTORY\n",
    "from utils.ner_utils import cluster_entities, process_sentences_and_extract_entities\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "# Carga de modelos y tokenizers\n",
    "roberta_model_name = \"PlanTL-GOB-ES/roberta-large-bne-capitel-ner\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "roberta_model = AutoModelForTokenClassification.from_pretrained(roberta_model_name)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Cargar los datos de las oraciones desde el archivo Excel\n",
    "    logging.info(\"Cargando datos de oraciones desde Excel...\")\n",
    "    sentence_data = read_excel_file(os.path.join(XLSX_DIRECTORY, \"sentence.xlsx\"))\n",
    "\n",
    "    # Realizar NER con RoBERTa\n",
    "    logging.info(\"Realizando NER con RoBERTa...\")\n",
    "    roberta_entities_df = process_sentences_and_extract_entities(\n",
    "        sentence_data,\n",
    "        roberta_tokenizer,\n",
    "        roberta_model,\n",
    "        perform_ner_with_roberta,\n",
    "        \"roberta\",\n",
    "    )\n",
    "\n",
    "    # Convertir DataFrame de entidades a lista de diccionarios para el clustering\n",
    "    roberta_entities_df = roberta_entities_df.to_dict(\"records\")\n",
    "\n",
    "    # Opcional: Agrupar entidades similares con K-means\n",
    "    logging.info(\"Agrupando entidades similares...\")\n",
    "    roberta_entities_df = cluster_entities(roberta_entities_df, num_clusters=10)\n",
    "\n",
    "    # Guardar los datos de entidades RoBERTa en un nuevo archivo Excel\n",
    "    logging.info(\"Guardando datos de entidades RoBERTa en Excel...\")\n",
    "    save_data_to_excel(roberta_entities_df, XLSX_DIRECTORY, \"roberta_entity.xlsx\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
