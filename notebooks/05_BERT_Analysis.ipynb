{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 17:35:39,242 - INFO - loading weights file pytorch_model.bin from cache at C:\\Users\\User\\.cache\\huggingface\\hub\\models--mrm8488--bert-spanish-cased-finetuned-ner\\snapshots\\b11721d41d9e948da32fcdabeeef4fb0f3ebcdf7\\pytorch_model.bin\n",
      "2024-01-21 17:35:39,714 - WARNING - Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2024-01-21 17:35:39,715 - INFO - All the weights of BertForTokenClassification were initialized from the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "2024-01-21 17:35:39,721 - INFO - Cargando datos de oraciones desde Excel...\n",
      "2024-01-21 17:35:40,598 - INFO - Realizando NER con BERT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 0/2208 oraciones (0.00%)\n",
      "Procesando: 220/2208 oraciones (9.96%)\n",
      "Procesando: 440/2208 oraciones (19.93%)\n",
      "\n",
      "Entidad 'San  de Miraflores' no encontrada en el texto.\n",
      "Contexto: primer puesto de su promoción [ENTIDAD] está por culminar sus estudios\n",
      "Oración: Abigail, de 17 años está por culminar sus estudios en la escuela César Vallejo, en San Juan de Miraflores; ella es brigadier general y primer puesto de su promoción.\n",
      "Omitiendo la adición de la entidad 'San  de Miraflores' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'San  de Miraflores' no encontrada en el texto.\n",
      "Contexto: en San Juan de Miraflores [ENTIDAD] la intervención de Essalud,\n",
      "Oración: A esto debe sumarse la intervención de Essalud, que construirá el Instituto de Medicina Deportiva y Rehabilitación en San Juan de Miraflores.\n",
      "Omitiendo la adición de la entidad 'San  de Miraflores' ya que no se encontró en el texto.\n",
      "Procesando: 660/2208 oraciones (29.89%)\n",
      "Procesando: 880/2208 oraciones (39.86%)\n",
      "\n",
      "Entidad 'UD E  SOCIAL' no encontrada en el texto.\n",
      "Contexto: ..... [ENTIDAD] INCLUSIÓN SOCIAL...\n",
      "Oración: 21 SALUD E INCLUSIÓN SOCIAL ............................................\n",
      "Omitiendo la adición de la entidad 'UD E  SOCIAL' ya que no se encontró en el texto.\n",
      "Procesando: 1100/2208 oraciones (49.82%)\n",
      "Procesando: 1320/2208 oraciones (59.78%)\n",
      "\n",
      "Entidad 'Aeropuerto Internacional  Chávez' no encontrada en el texto.\n",
      "Contexto: servicio para el año 2022 [ENTIDAD] de la segunda pista de\n",
      "Oración: Está en marcha la construcción de la segunda pista de aterrizaje y del nuevo terminal de pasajeros del Aeropuerto Internacional Jorge Chávez, lo que garantiza su culminación y puesta en servicio para el año 2022.\n",
      "Omitiendo la adición de la entidad 'Aeropuerto Internacional  Chávez' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'Decreto de Urgencia -' no encontrada en el texto.\n",
      "Contexto: del derecho a la salud [ENTIDAD] mediante Decreto de Urgencia 017\n",
      "Oración: En octubre del 2019, mediante Decreto de Urgencia 017-2019, se declaró a los medicamentos, productos biológicos y dispositivos médicos como parte esencial del derecho a la salud.\n",
      "Omitiendo la adición de la entidad 'Decreto de Urgencia -' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'Decreto de Urgencia -2020' no encontrada en el texto.\n",
      "Contexto: de 10 regiones del país [ENTIDAD] de Urgencia 071 - 2020\n",
      "Oración: Por ello aprobamos el Decreto de Urgencia 071-2020 que establece el Plan de Intervención para Comunidades Indígenas y Centros Poblados Rurales de la Amazonía frente a la Emergencia COVID-19, plan que cuenta con un financiamiento de 74 millones de soles y se encuentra dirigido a 350 mil ciudadanos de comunidades indígenas en 5,351 centros poblados de 10 regiones del país.\n",
      "Omitiendo la adición de la entidad 'Decreto de Urgencia -2020' ya que no se encontró en el texto.\n",
      "Procesando: 1540/2208 oraciones (69.75%)\n",
      "Procesando: 1760/2208 oraciones (79.71%)\n",
      "\n",
      "Entidad 'Ministerio de Ciencia , Tecnología' no encontrada en el texto.\n",
      "Contexto: , Tecnología e Innovación Tecnológica [ENTIDAD], mi gobierno propondrá la\n",
      "Oración: Para hacer frente a estos desafíos, mi gobierno propondrá la creación del Ministerio de Ciencia, Tecnología e Innovación Tecnológica.\n",
      "Omitiendo la adición de la entidad 'Ministerio de Ciencia , Tecnología' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'Sistema Informático  Perú' no encontrada en el texto.\n",
      "Contexto: de 99 millones de soles [ENTIDAD] fecha, 3, 530\n",
      "Oración: Pá gi n a 11 69Hasta la fecha, 3,530 ollas comunes se encuentran registradas en el Sistema Informático Mankachay Perú, dirigidas por abnegadas madres y mujeres peruanas, las cuales atienden a 217,000 beneficiarios, para quienes se ha destinado ya un presupuesto de 99 millones de soles.\n",
      "Omitiendo la adición de la entidad 'Sistema Informático  Perú' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'Decreto de Urgencia N -2022' no encontrada en el texto.\n",
      "Contexto: 65 y el Programa Contigo [ENTIDAD] N 07 - 2022 se\n",
      "Oración: Con el Decreto de Urgencia N 07-2022 se entregó un apoyo económico extraordinario a más de 1 millón 300 mil usuarios de los programas sociales Juntos, Pensión 65 y el Programa Contigo.\n",
      "Omitiendo la adición de la entidad 'Decreto de Urgencia N -2022' ya que no se encontró en el texto.\n",
      "Procesando: 1980/2208 oraciones (89.67%)\n",
      "\n",
      "Entidad 'LA  RURAL' no encontrada en el texto.\n",
      "Contexto: las 24 regiones del Perú [ENTIDAD] RURAL Se tienen 1,\n",
      "Oración: LA ELECTRIFICACIÓN RURAL Se tienen 1,948 millones de soles financiando 117 proyectos de electrificación, en las 24 regiones del Perú.\n",
      "Omitiendo la adición de la entidad 'LA  RURAL' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'Política del Desarrollo Agrario , Rural' no encontrada en el texto.\n",
      "Contexto: diversidad que posee nuestro país [ENTIDAD] una Política del Desarrollo Agrario\n",
      "Oración: El compromiso del sector es llevar adelante una Política del Desarrollo Agrario, Rural, participativo de abajo Pá gi n a 23 69hacia arriba y de adentro hacia afuera, con enfoque territorial, tomando en cuenta la gran diversidad que posee nuestro país.\n",
      "Omitiendo la adición de la entidad 'Política del Desarrollo Agrario , Rural' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'cal Don Antonio  de Sucre' no encontrada en el texto.\n",
      "Contexto: histórica Pampa de la Quinua [ENTIDAD] decisivo, cabe una reflexión\n",
      "Oración: Pero, también, en este momento decisivo, cabe una reflexión serena sobre nuestra historia y el significado de un hito de nuestro pasado la próxima conmemoración, el 9 de diciembre del 2024, del Bicentenario de la gran Batalla de Ayacucho, último grito de libertad lanzado a todo pulmón en América del Sur, luego de la victoria de los guerreros del Mariscal Don Antonio José de Sucre; de los generales Agustín Gamarra, José de la Mar, José María Córdova, Jacinto Lara y William Miller, en la histórica Pampa de la Quinua.\n",
      "Omitiendo la adición de la entidad 'cal Don Antonio  de Sucre' ya que no se encontró en el texto.\n",
      "\n",
      "Entidad 'RTE III Del Dicho al Hecho , Cumpliendo Compromisos' no encontrada en el texto.\n",
      "Contexto: la gestión de mi Gobierno [ENTIDAD] Luego de dar cuenta de\n",
      "Oración: 16PARTE III Del Dicho al Hecho, Cumpliendo Compromisos Luego de dar cuenta de los impactos de las continuas adversidades que estamos padeciendo y de la respuesta del Estado, paso ahora a exponer algunos resultados positivos de la gestión de mi Gobierno.\n",
      "Omitiendo la adición de la entidad 'RTE III Del Dicho al Hecho , Cumpliendo Compromisos' ya que no se encontró en el texto.\n",
      "Procesando: 2200/2208 oraciones (99.64%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 17:40:36,511 - INFO - Agrupando entidades similares...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entidad 'lace de 500  Celendín' no encontrada en el texto.\n",
      "Contexto: en 54 millones de dólares [ENTIDAD] destacan el Enlace de 500\n",
      "Oración: Entre esos proyectos destacan el Enlace de 500 kilovatios Huánuco-Tocache-Celendín-Trujillo, que se ejecutará con una inversión estimada de 486 millones de dólares; el Enlace de 500 kilovatios Celendín-Piura, que demanda una inversión estimada de 234 millones de dólares; y, el Enlace 220 kilovatios Ica-Poroma, que significará una inversión estimada en 54 millones de dólares.\n",
      "Omitiendo la adición de la entidad 'lace de 500  Celendín' ya que no se encontró en el texto.\n",
      "Procesamiento completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TFM_Project\\PLN_Project\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "2024-01-21 17:40:37,046 - INFO - Guardando datos de entidades BERT en Excel...\n",
      "2024-01-21 17:40:37,606 - INFO - DataFrame guardado en d:\\TFM_Project\\PLN_Project\\data\\xlsx\\bert_entity.xlsx\n"
     ]
    }
   ],
   "source": [
    "# notebooks/04_BERT_Analysis.ipynb\n",
    "# Importar las bibliotecas necesarias\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración del entorno del notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils.file_utils import read_excel_file, save_data_to_excel\n",
    "from utils.advanced_ner_utils import (\n",
    "    perform_ner_with_bert,\n",
    "    process_sentences_and_extract_entities,\n",
    ")\n",
    "\n",
    "from config import XLSX_DIRECTORY\n",
    "from utils.ner_utils import cluster_entities\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "\n",
    "# Carga de modelos y tokenizers\n",
    "bert_model_name = \"mrm8488/bert-spanish-cased-finetuned-ner\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertForTokenClassification.from_pretrained(bert_model_name)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Cargar los datos de las oraciones desde el archivo Excel\n",
    "    logging.info(\"Cargando datos de oraciones desde Excel...\")\n",
    "    sentence_data = read_excel_file(os.path.join(XLSX_DIRECTORY, \"sentence.xlsx\"))\n",
    "    # sentence_data = read_excel_file(os.path.join(XLSX_DIRECTORY, \"sentence_2.xlsx\"))\n",
    "\n",
    "    # Realizar NER con BERT\n",
    "    logging.info(\"Realizando NER con BERT...\")\n",
    "    bert_entities_df = process_sentences_and_extract_entities(\n",
    "        sentence_data, bert_tokenizer, bert_model, perform_ner_with_bert, \"bert\"\n",
    "    )\n",
    "\n",
    "    # Convertir DataFrame de entidades a lista de diccionarios para el clustering\n",
    "    bert_entities_df = bert_entities_df.to_dict(\"records\")\n",
    "\n",
    "    # Opcional: Agrupar entidades similares con K-means\n",
    "    logging.info(\"Agrupando entidades similares...\")\n",
    "    bert_entities_df = cluster_entities(bert_entities_df, num_clusters=10)\n",
    "\n",
    "    # Guardar los datos de entidades BERT en un nuevo archivo Excel\n",
    "    logging.info(\"Guardando datos de entidades BERT en Excel...\")\n",
    "    save_data_to_excel(bert_entities_df, XLSX_DIRECTORY, \"bert_entity.xlsx\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "# pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 18:12:09,174 - INFO - loading weights file pytorch_model.bin from cache at C:\\Users\\User\\.cache\\huggingface\\hub\\models--mrm8488--bert-spanish-cased-finetuned-ner\\snapshots\\b11721d41d9e948da32fcdabeeef4fb0f3ebcdf7\\pytorch_model.bin\n",
      "2024-01-18 18:12:09,567 - WARNING - Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2024-01-18 18:12:09,570 - INFO - All the weights of BertForTokenClassification were initialized from the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "Yo: O\n",
      "siempre: O\n",
      "digo: O\n",
      ",: O\n",
      "lo: O\n",
      "hablo: O\n",
      "mucho: O\n",
      "con: O\n",
      "los: O\n",
      "gobernadores: O\n",
      ",: O\n",
      "acá: O\n",
      "está: O\n",
      "el: O\n",
      "Gobernador de Tucumán: B-PER\n",
      ",: O\n",
      "y: O\n",
      "lo: O\n",
      "hablo: O\n",
      "con: O\n",
      "muchos: O\n",
      "inten: O\n",
      "##dentes: O\n",
      ",: O\n",
      "algunos: O\n",
      "los: O\n",
      "veo: O\n",
      "por: O\n",
      "allí: O\n",
      ",: O\n",
      "lo: O\n",
      "veo: O\n",
      "a: O\n",
      "Lucas: B-PER\n",
      ",: O\n",
      "lo: O\n",
      "veo: O\n",
      "a: O\n",
      "Andrés: B-PER\n",
      ",: O\n",
      "lo: O\n",
      "veo: O\n",
      "a: O\n",
      "[UNK]: B-PER\n",
      ",: O\n",
      "y: O\n",
      "lo: O\n",
      "hablo: O\n",
      "con: O\n",
      "muchos: O\n",
      "de: O\n",
      "ellos: O\n",
      ".: O\n",
      "[SEP]: O\n",
      "['Yo', 'siempre', 'digo', ',', 'lo', 'hablo', 'mucho', 'con', 'los', 'gobernadores', ',', 'acá', 'está', 'el', 'Gobernador', 'de', 'Tucumán', ',', 'y', 'lo', 'hablo', 'con', 'muchos', 'inten', '##dentes', ',', 'algunos', 'los', 'veo', 'por', 'allí', ',', 'lo', 'veo', 'a', 'Lucas', ',', 'lo', 'veo', 'a', 'Andrés', ',', 'lo', 'veo', 'a', '[UNK]', ',', 'y', 'lo', 'hablo', 'con', 'muchos', 'de', 'ellos', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "bert_model_name = \"mrm8488/bert-spanish-cased-finetuned-ner\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertForTokenClassification.from_pretrained(bert_model_name)\n",
    "\n",
    "# Texto a analizar\n",
    "text = \"Yo siempre digo, lo hablo mucho con los gobernadores, acá está el Gobernador de Tucumán, y lo hablo con muchos intendentes, algunos los veo por allí, lo veo a Lucas, lo veo a Andrés, lo veo a Julio, y lo hablo con muchos de ellos.\"\n",
    "\n",
    "# Codificar el texto\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "# Predicciones del modelo\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)[0]\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "# Función para reconstruir las entidades a partir de subtokens\n",
    "def reconstruct_entities(tokens, predictions, tokenizer, model):\n",
    "    new_tokens, new_labels = [], []\n",
    "    for token, prediction in zip(tokens, predictions[0]):\n",
    "        token_str = tokenizer.decode([token], skip_special_tokens=False)\n",
    "        label = model.config.id2label[prediction.item()]\n",
    "\n",
    "        # Reconstruir la entidad, incluyendo [UNK] si está rodeado por subtokens de la misma entidad\n",
    "        if new_labels and label.startswith(\"I-\") and new_labels[-1].endswith(label.split(\"-\")[-1]):\n",
    "            if token_str != tokenizer.unk_token or (new_tokens[-1] != tokenizer.unk_token and token_str == tokenizer.unk_token):\n",
    "                new_tokens[-1] = new_tokens[-1] + \" \" + token_str\n",
    "            else:\n",
    "                new_tokens[-1] += token_str\n",
    "        else:\n",
    "            new_tokens.append(token_str)\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_tokens, new_labels\n",
    "\n",
    "\n",
    "# Reconstruir entidades\n",
    "new_tokens, new_labels = reconstruct_entities(inputs[0], predictions, tokenizer, model)\n",
    "\n",
    "# Imprimir tokens y sus etiquetas\n",
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(f\"{token}: {label}\")\n",
    "print(tokenizer.tokenize(text))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
